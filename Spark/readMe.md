spark是一个计算框架，分为spark-core，saprk-sql，spark-streaming，spark-Elib，spark-graphX。
可以看做是Hadoop的一个改良框架。相比于handoop的硬盘计算，spark使用内存计算使其更快。但是因为这一点，在集群计算时可能会抢占更多资源导致不稳定，所以spark不能完全代替hadoop
